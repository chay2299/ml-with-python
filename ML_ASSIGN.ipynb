{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f394e541-e130-411f-b68f-47c9a49c3f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.16.1\n",
      "Keras Version: 3.3.3\n",
      "\n",
      "Python 3.9.19 (main, Mar 21 2024, 12:07:41) \n",
      "[Clang 14.0.6 ]\n",
      "Pandas 2.2.2\n",
      "Scikit-Learn 1.4.2\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963f0875-8ef2-4f72-ac3d-4e350d878bbb",
   "metadata": {},
   "source": [
    "# READING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a44d02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import sklearn\n",
    "# import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Check for TensorFlow GPU access\n",
    "# print(f\"TensorFlow has access to the following devices:\\n{tf.config.list_physical_devices()}\")\n",
    "\n",
    "# # See TensorFlow version\n",
    "# print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9c7f612-c391-4762-a83c-7afa2ee9e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13076d17-79dd-4189-89ec-8f3e7a92e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/users/likeshkoya/downloads/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7053770-3d8e-4efa-bd87-37ac39353c21",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df51c93-4749-4d7e-8583-fbf8e2f996b2",
   "metadata": {},
   "source": [
    "## CHECKING AND REMOVING NULL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90c7192e-6ac7-4ae0-a697-bf65e5dc9b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "teacher_id                                          0\n",
       "teacher_prefix                                      3\n",
       "school_state                                        0\n",
       "project_submitted_datetime                          0\n",
       "project_grade_category                              0\n",
       "project_subject_categories                          0\n",
       "project_subject_subcategories                       0\n",
       "project_title                                       0\n",
       "project_essay_1                                     0\n",
       "project_essay_2                                     0\n",
       "project_essay_3                                 84325\n",
       "project_essay_4                                 84325\n",
       "project_resource_summary                            0\n",
       "teacher_number_of_previously_posted_projects        0\n",
       "project_is_approved                                 0\n",
       "total_quantity                                      0\n",
       "total_price                                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5159ff97-b639-401d-8c0d-d74cb10666c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['teacher_prefix'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "648bcf44-45a2-46d2-8b4f-4f4ed5f215df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c6c36c-8701-461c-b44e-abf34f22154e",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfebee67-e380-425b-afc5-57cbcba72d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"full_eassay\"] = df[[\"project_essay_1\",\"project_essay_2\",\"project_essay_3\",\"project_essay_4\",\"project_resource_summary\",\"project_subject_categories\",\"project_subject_subcategories\", 'project_title']].agg(\" \".join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cbfaab2-6d6b-489f-b4d8-08d93c71cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['project_essay_1', 'project_essay_2','project_essay_3','project_essay_4','project_resource_summary','project_subject_categories', 'project_subject_subcategories', 'project_title'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fb1960-a3a5-453f-8205-460579cb8490",
   "metadata": {},
   "source": [
    "## FEATURE ENCODING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbc7786-4f5e-4f9c-b40a-443a47e16961",
   "metadata": {},
   "source": [
    "### removing the unnecessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3112dc8-f465-48e6-a1c0-8770469ca16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_eassay'] = df['full_eassay'].apply(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2156a699-58a8-4ba3-a838-230daca6778b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/likeshkoya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "\n",
    "    words = nltk.word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text\n",
    "\n",
    "df['full_eassay'] = df['full_eassay'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58883a36-cc82-4987-969d-1a2506e52304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_non_alpha(text):\n",
    "\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "df['text_column_cleaned'] = df['full_eassay'].apply(remove_non_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "722c412a-7a49-4c97-a9ac-8af4922c47f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/likeshkoya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/likeshkoya/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "def lemmatize_word(word):\n",
    "    return wnl.lemmatize(word, pos=\"v\")\n",
    "\n",
    "df['lemmatized_text'] = df['text_column_cleaned'].apply(lemmatize_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83c51bb8-c003-4c8e-802f-3a70762ca05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/likeshkoya/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "\n",
    "english_words = set(nltk.corpus.words.words())\n",
    "\n",
    "def extract_dictionary_words(text):\n",
    "    \n",
    "    words = nltk.word_tokenize(text)\n",
    "    dict_words = [word for word in words if word.lower() in english_words]\n",
    "    return dict_words\n",
    "\n",
    "df['lemmatized_text'] = df['lemmatized_text'].apply(extract_dictionary_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fdb8390-d22d-4259-b2aa-8eed014fff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def con(words):\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['lemmatized_text'] = df['lemmatized_text'].apply(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7013b091-76a8-4678-8993-4b5cae6ba26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv.fit(df['lemmatized_text'])\n",
    "\n",
    "def process_chunk(chunk):\n",
    "   \n",
    "    X_chunk = pd.DataFrame(cv.transform(chunk['lemmatized_text']).todense(), columns=sorted(cv.vocabulary_))\n",
    "    return X_chunk\n",
    "\n",
    "chunk_size = 1000\n",
    "\n",
    "chunks = [df[i:i+chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "\n",
    "result_chunks = [process_chunk(chunk) for chunk in chunks]\n",
    "final_result = pd.concat(result_chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87dc858-3bd0-4a47-b430-19182373f363",
   "metadata": {},
   "source": [
    "### Reducing the number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5391970-f54f-492d-b7e7-f8b23d5a9f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_sum=final_result.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1d065ef-8d0d-4878-9a59-066e8c99d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_less_than_mean(df):\n",
    "    \n",
    "    column_sums = df.sum(axis=0)\n",
    "    mean_column_sum = column_sums.mean()\n",
    "    columns_to_drop = column_sums[column_sums < mean_column_sum*0.25].index\n",
    "    \n",
    "    df.drop(columns=columns_to_drop, inplace=True)\n",
    "    return df\n",
    "final_result=drop_columns_less_than_mean(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff0b16cc-ba31-44bc-bcd0-575f27de024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=final_result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c862cfe9-265d-415f-9e62-93646c623624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ability', 'able', 'absent', 'absolute', 'absolutely', 'absorb',\n",
       "       'abstract', 'abundance', 'abuse', 'academic',\n",
       "       ...\n",
       "       'yoga', 'york', 'young', 'younger', 'youth', 'zero', 'zest', 'zip',\n",
       "       'zone', 'zoo'],\n",
       "      dtype='object', length=3598)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcab0e8e-2246-4d01-8f39-eaf1093f8bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, final_result], axis = 1).drop(columns = ['lemmatized_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a9eda7-5213-4c2a-acca-0714a6048f67",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e837ab7f-68b7-4017-a6ff-4c66df608a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output = False).set_output(transform = 'pandas')\n",
    "ohetransform = ohe.fit_transform(df[['school_state']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7381dab-70ef-4d91-944e-4f4e6abbc540",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output = False).set_output(transform = 'pandas')\n",
    "ohetransformed = ohe.fit_transform(df[['project_grade_category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d236f33-2d59-4175-a832-69f8a7ef05cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output = False).set_output(transform = 'pandas')\n",
    "ohetransform = ohe.fit_transform(df[['school_state']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8dfff211-e271-4f99-86d9-956c4d572bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_decimal(hex):\n",
    "    return int(hex, 16)\n",
    "\n",
    "df['teacher_id_no'] = df['teacher_id'].apply(hex_to_decimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f20b2779-aa6f-48a0-84c1-971864d70257",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['teacher_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00a036d-f77c-472e-84bf-26d9fa85d20e",
   "metadata": {},
   "source": [
    "### Concantination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b9b4d27-273f-4fd1-bb46-ef52d0bb63b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, ohetransform ], axis = 1).drop(columns = ['school_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc4e08e3-bf36-4b60-b86e-98484264ad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, ohetransformed ], axis = 1).drop(columns = ['project_grade_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f3c9c22-fab5-45f4-a504-e1008913841b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87398 entries, 0 to 87397\n",
      "Columns: 3661 entries, project_submitted_datetime to project_grade_category_Grades PreK-2\n",
      "dtypes: float64(56), int64(3601), object(4)\n",
      "memory usage: 2.4+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93b02e5f-4b4c-49cb-9a8d-a0a3974d0a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1fa7867-ffa9-4f2d-b9ea-cc7b69210453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>total_quantity</th>\n",
       "      <th>total_price</th>\n",
       "      <th>full_eassay</th>\n",
       "      <th>text_column_cleaned</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absent</th>\n",
       "      <th>...</th>\n",
       "      <th>school_state_VA</th>\n",
       "      <th>school_state_VT</th>\n",
       "      <th>school_state_WA</th>\n",
       "      <th>school_state_WI</th>\n",
       "      <th>school_state_WV</th>\n",
       "      <th>school_state_WY</th>\n",
       "      <th>project_grade_category_Grades 3-5</th>\n",
       "      <th>project_grade_category_Grades 6-8</th>\n",
       "      <th>project_grade_category_Grades 9-12</th>\n",
       "      <th>project_grade_category_Grades PreK-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-06-20 23:05:15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>264.99</td>\n",
       "      <td>\\ '' teacher next year , made science fun ? \\ ...</td>\n",
       "      <td>teacher next year  made science fun    asked...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-01 08:11:20</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>847.00</td>\n",
       "      <td>living poverty often means lack access things ...</td>\n",
       "      <td>living poverty often means lack access things ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-05-09 11:40:49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>222.20</td>\n",
       "      <td>high school speech debate team . qualified alt...</td>\n",
       "      <td>high school speech debate team  qualified alte...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-11-27 18:15:15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>318.97</td>\n",
       "      <td>students fun bunch diverse kids love school en...</td>\n",
       "      <td>students fun bunch diverse kids love school en...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-07-07 19:20:49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>606.41</td>\n",
       "      <td>students working hard increase reading levels ...</td>\n",
       "      <td>students working hard increase reading levels ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3661 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  project_submitted_datetime  teacher_number_of_previously_posted_projects  \\\n",
       "0        2016-06-20 23:05:15                                             0   \n",
       "1        2016-09-01 08:11:20                                            12   \n",
       "2        2016-05-09 11:40:49                                             1   \n",
       "3        2016-11-27 18:15:15                                             0   \n",
       "4        2016-07-07 19:20:49                                             0   \n",
       "\n",
       "   project_is_approved  total_quantity  total_price  \\\n",
       "0                    1               1       264.99   \n",
       "1                    1               5       847.00   \n",
       "2                    1              13       222.20   \n",
       "3                    1               5       318.97   \n",
       "4                    0              25       606.41   \n",
       "\n",
       "                                         full_eassay  \\\n",
       "0  \\ '' teacher next year , made science fun ? \\ ...   \n",
       "1  living poverty often means lack access things ...   \n",
       "2  high school speech debate team . qualified alt...   \n",
       "3  students fun bunch diverse kids love school en...   \n",
       "4  students working hard increase reading levels ...   \n",
       "\n",
       "                                 text_column_cleaned  ability  able  absent  \\\n",
       "0    teacher next year  made science fun    asked...        0     0       0   \n",
       "1  living poverty often means lack access things ...        0     1       0   \n",
       "2  high school speech debate team  qualified alte...        0     1       0   \n",
       "3  students fun bunch diverse kids love school en...        0     3       0   \n",
       "4  students working hard increase reading levels ...        1     3       0   \n",
       "\n",
       "   ...  school_state_VA  school_state_VT  school_state_WA  school_state_WI  \\\n",
       "0  ...              0.0              0.0              0.0              0.0   \n",
       "1  ...              0.0              0.0              0.0              0.0   \n",
       "2  ...              0.0              0.0              0.0              0.0   \n",
       "3  ...              0.0              0.0              0.0              0.0   \n",
       "4  ...              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   school_state_WV  school_state_WY  project_grade_category_Grades 3-5  \\\n",
       "0              0.0              0.0                                1.0   \n",
       "1              0.0              0.0                                0.0   \n",
       "2              0.0              0.0                                0.0   \n",
       "3              0.0              0.0                                0.0   \n",
       "4              0.0              0.0                                1.0   \n",
       "\n",
       "   project_grade_category_Grades 6-8  project_grade_category_Grades 9-12  \\\n",
       "0                                0.0                                 0.0   \n",
       "1                                0.0                                 0.0   \n",
       "2                                0.0                                 1.0   \n",
       "3                                0.0                                 0.0   \n",
       "4                                0.0                                 0.0   \n",
       "\n",
       "   project_grade_category_Grades PreK-2  \n",
       "0                                   0.0  \n",
       "1                                   1.0  \n",
       "2                                   0.0  \n",
       "3                                   1.0  \n",
       "4                                   0.0  \n",
       "\n",
       "[5 rows x 3661 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9af89e2-dfaa-41ba-bf92-f57d0747f7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['project_submitted_datetime','full_eassay','text_column_cleaned'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b11902f8-a5dc-4e9b-823e-64f7630a23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('like.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b60aae-851b-4766-a59f-c6909f9356b9",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ab72b1b-ae6a-423b-b55a-f5af4fae3bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['project_is_approved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de9ca7de-9930-42ea-99f5-1383963603af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('project_is_approved', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4dc2a10d-b3e6-4dea-acd6-68f7c5912436",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_columns_names=X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b5eb594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53012a09-703e-4a23-9e62-8953b0a36a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_train_resampled, y_train_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# n_estimators = 100 \n",
    "# learning_rate = 1.0  \n",
    "\n",
    "# adaboost_clf = AdaBoostClassifier(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "\n",
    "# adaboost_clf.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = adaboost_clf.predict(X_test)\n",
    "\n",
    "# precision = precision_score(y_test, y_pred)\n",
    "# recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# print(\"Precision:\", precision)\n",
    "# print(\"Recall:\", recall)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X and Y are defined somewhere before this point\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_resampled, y_train_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_dist = {\n",
    "    'n_estimators': randint(10, 200),  # Number of trees in the forest\n",
    "    'max_depth': [None] + list(np.arange(3, 21)),  # Maximum depth of the tree\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider at every split\n",
    "    'min_samples_split': randint(2, 20),  # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': randint(1, 20),  # Minimum number of samples required at each leaf node\n",
    "    'bootstrap': [True, False]  # Method of selecting samples for training each tree\n",
    "}\n",
    "\n",
    "# Create a Random Forest classifier instance\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Randomized search cross validation\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=100, cv=5, verbose=1, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters found\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# Best cross-validation score found\n",
    "print(\"Best Score:\", random_search.best_score_)\n",
    "\n",
    "# Get the best estimator\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Now you can use 'best_rf' for predictions or further analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ce7839-27d0-4aae-8fcc-fdcac0d84cc0",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77567f1-12f1-487d-ba4c-fa21ce013701",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/users/likeshkoya/downloads/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408e4f12-5de7-4b27-9221-44ebc2c620a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "backup = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8092f979-8b79-40c3-81fa-3c136b76cfe3",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707ecdfb-3f63-4fa0-a3b7-b55b025a21b7",
   "metadata": {},
   "source": [
    "## CHECKING AND REMOVING NULL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5c297a-16f6-4b02-9872-f86c64d4c9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216d20ed-442f-4793-a3be-69e758ce50da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(['teacher_prefix'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82313ded-87b8-428e-91dc-b91de2d853fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180da483",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f448ae8-4f0a-433b-819f-b5a588ee3689",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e4f81-ad1a-440a-a564-65f736410082",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"full_eassay\"] = df_test[[\"project_essay_1\",\"project_essay_2\",\"project_essay_3\",\"project_essay_4\",\"project_resource_summary\",\"project_subject_categories\",\"project_subject_subcategories\", 'project_title']].agg(\" \".join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf3f7df-b4b0-4e44-871b-d8740677c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(['project_essay_1', 'project_essay_2','project_essay_3','project_essay_4','project_resource_summary','project_subject_categories', 'project_subject_subcategories', 'project_title'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88147777-3d7b-47cc-8891-6ab91e362e0f",
   "metadata": {},
   "source": [
    "## FEATURE ENCODING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95de3f6-5b48-4ba1-abe3-279205ada689",
   "metadata": {},
   "source": [
    "### removing the unnecessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66418a8-24d8-4fa6-983a-f20c8efb15d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['full_eassay'] = df_test['full_eassay'].apply(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e377366",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad127264-23a6-4391-ae3f-683dbf13d563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "\n",
    "    words = nltk.word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text\n",
    "\n",
    "df_test['full_eassay'] = df_test['full_eassay'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c153a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39ddd8e-7b68-4d29-b004-e5e0a539ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_non_alpha(text):\n",
    "\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "df_test['text_column_cleaned'] = df_test['full_eassay'].apply(remove_non_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b247a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056acc0c-4299-4cf1-88f0-9ef62f2c4154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "def lemmatize_word(word):\n",
    "    return wnl.lemmatize(word, pos=\"v\")\n",
    "\n",
    "df_test['lemmatized_text'] = df_test['text_column_cleaned'].apply(lemmatize_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae4f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103655e8-7680-4b7f-beed-826f4d27c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('words')\n",
    "\n",
    "english_words = set(nltk.corpus.words.words())\n",
    "\n",
    "def extract_dictionary_words(text):\n",
    "    \n",
    "    words = nltk.word_tokenize(text)\n",
    "    dict_words = [word for word in words if word.lower() in english_words]\n",
    "    return dict_words\n",
    "\n",
    "df_test['lemmatized_text'] = df_test['lemmatized_text'].apply(extract_dictionary_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ad51bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c31751-b582-4def-80f8-aec8e6a6ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def con(words):\n",
    "    return ' '.join(words)\n",
    "\n",
    "df_test['lemmatized_text'] = df_test['lemmatized_text'].apply(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab44df4-8418-46ef-9fea-0c600c82281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv.fit(df_test['lemmatized_text'])\n",
    "\n",
    "def process_chunk(chunk):\n",
    "   \n",
    "    X_chunk = pd.DataFrame(cv.transform(chunk['lemmatized_text']).todense(), columns=sorted(cv.vocabulary_))\n",
    "    return X_chunk\n",
    "\n",
    "chunk_size = 1000\n",
    "\n",
    "chunks = [df_test[i:i+chunk_size] for i in range(0, len(df_test), chunk_size)]\n",
    "\n",
    "result_chunks = [process_chunk(chunk) for chunk in chunks]\n",
    "final_result = pd.concat(result_chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7fa1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328c4d75-4807-4e18-a718-61530fcb73d5",
   "metadata": {},
   "source": [
    "### Reducing the number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee74653-a852-4dc5-88a5-2b6a13e5dc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd0208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2f6eaa-b2ca-49d3-bbd9-0fac9d317991",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdd3600",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90c917a-3b53-4da5-835e-d75ba1c17c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_not_in_train_data(df):\n",
    "    \n",
    "    columns_not_to_drop = feature_names\n",
    "    \n",
    "    to_drop_df = df.drop(columns=columns_not_to_drop)\n",
    "    columns_to_drop = to_drop_df.columns\n",
    "    df.drop(columns=columns_to_drop, inplace = True)\n",
    "    return df\n",
    "final_result=drop_columns_not_in_train_data(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9197b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7058c6e-edea-4894-a8fd-3d80a8e17de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391c552e-ad5e-479d-9cb3-31fee232f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9452f406-fe30-449b-9d8e-174e83468622",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([df_test, final_result], axis = 1).drop(columns = ['lemmatized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46628a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152af540-7645-4b95-8229-0bf5e6bb2f5d",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d62b547-92c6-42ac-bd79-46c2924044cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output = False).set_output(transform = 'pandas')\n",
    "ohetransform_test_schoolstate = ohe.fit_transform(df_test[['school_state']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aac893",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0318d2-09dc-4edc-9c5d-bc5fdd163c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output = False).set_output(transform = 'pandas')\n",
    "ohetransform_test_grade = ohe.fit_transform(df_test[['project_grade_category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb78f34",
   "metadata": {},
   "outputs": [],
   "source": [
    " df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c0b13f-c8f6-446d-ac45-ac09cfb5ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_decimal(hex):\n",
    "    return int(hex, 16)\n",
    "\n",
    "df_test['teacher_id_no'] = df_test['teacher_id'].apply(hex_to_decimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987fa8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c71d46e-943f-4f3b-804d-d952e952595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(['teacher_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3869f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7282f36c-6abe-43ad-a364-dfc3d068dfa2",
   "metadata": {},
   "source": [
    "### Concantination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be66f8e-480b-4165-93e4-dc6bb70ae8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([df_test, ohetransform_test_schoolstate ], axis = 1).drop(columns = ['school_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0404f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911949a5-d4a5-4d4c-b1c3-26c8cbd1ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([df_test, ohetransform_test_grade ], axis = 1).drop(columns = ['project_grade_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d69accd-1538-4a85-9d10-d42154ab3f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f2099-73f9-4fd9-ac69-2c503eabae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc21071-5779-4e2a-8773-254c91516edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d981823-bf66-431a-931b-2e48fe361b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(['project_submitted_datetime','full_eassay','text_column_cleaned'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dcc2b9-a5a8-477d-ae94-a62615cf270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_not_in_train_data(df):\n",
    "    \n",
    "    columns_not_to_drop = all_train_columns_names\n",
    "    \n",
    "    to_drop_df = df.drop(columns=columns_not_to_drop)\n",
    "    columns_to_drop = to_drop_df.columns\n",
    "    df.drop(columns=columns_to_drop, inplace = True)\n",
    "    return df\n",
    "df_test=drop_columns_not_in_train_data(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0277c3-b6a2-44df-badf-c55aec6829cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_columns_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fb34c8-9527-44a0-b8aa-d796cca5431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea259a1-4ecc-40e1-95a3-78223823c0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd8824-ad63-4b91-b02b-2dce84f70994",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b2106-8cea-45cf-b72b-ffaed0a371c5",
   "metadata": {},
   "source": [
    "# Predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6751af8-4a36-4d63-9f55-d5dc72282e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = best_rf.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fc1efa-5d7d-44ca-9568-f9059bf8b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "guhdjsahjk = pd.DataFrame(y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49450c6c-e190-4949-b952-13ba350e5337",
   "metadata": {},
   "outputs": [],
   "source": [
    "backup=pd.concat([backup, guhdjsahjk ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f0c1d9-f6df-4e82-a2a9-2c3ed02c7d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "guhdjsahjk.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d812c1a-a9eb-4472-837b-18a0fb18aa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "guhdjsahjk.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f93450-7e08-4f50-b336-d3245a594aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "guhdjsahjk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3849bbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "zeros_count = guhdjsahjk.iloc[:, 0].value_counts().get(0, 0)\n",
    "ones_count = guhdjsahjk.iloc[:, 0].value_counts().get(1, 0)\n",
    "\n",
    "print(\"Number of zeros in the first column:\", zeros_count)\n",
    "print(\"Number of ones in the first column:\", ones_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad8fb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c6f7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_df = pd.DataFrame({'predicted_label': y_prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a723d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_df.to_csv('predict_se21uari210.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f602ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7742b8c-7092-424d-b6e8-cadc1d73ec7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e67c3-e16a-413e-96b3-52192a942b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d468e41-8fad-409d-a3d6-daa24a9eadf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f87d75-1058-4e9d-8b01-cb3dd7fb7286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495268ff-7d9b-4e43-86c8-4d6cdef0c137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyhton 3.9 (tensorflow)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
